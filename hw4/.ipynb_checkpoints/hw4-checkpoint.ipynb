{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 152 Homework 4  Video Understanding\n",
    "\n",
    "In this homework, you will use the tools learned in class to solve object tracking and object discovery problems.\n",
    "\n",
    "The due for this homework is scheduled one day after the final exam, which is ``Dec. 10th, 11:59 pm``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter, convolve\n",
    "import scipy\n",
    "import warnings\n",
    "from skimage.io import *\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2\n",
    "from skimage import filters\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Iterative KLT tracker (70 pts)\n",
    "\n",
    "In this question, you will track a specific object in a given video (test.avi) by implementing an iterative KLT tracker. The KLT tracker works on two frames at a time, and estimates\n",
    "the deformation between two image frames under the assumption that the\n",
    "intensity of the objects has not changed significantly between the two frames.\n",
    "In this homework, we assume the motion is translation only (the matrix\n",
    "$P$ we learned from class is a translation matrix here). \n",
    "\n",
    "Starting with a\n",
    "rectangle $R_t$ on frame $I_t$, the KLT tracker aims to move it by an offset $(u, v)$ to\n",
    "obtain another rectangle $R_{t+1}$ on frame I_{t+1}, so that the pixel squared difference\n",
    "in the two rectangles is minimized:\n",
    "$$min_{u, v} J(u, v) = \\Sigma_{x, y \\in R_t}(I(x+u, y+v)-I(x, y))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1: Preliminary [10 pts]\n",
    "Starting with an initial guess of $(u, v)$ (usually $(0,0)$), we can compute the\n",
    "optimal $(u^∗\n",
    ", v^∗\n",
    ")$ iteratively. In each iteration, the objective function is locally\n",
    "linearized by first-order Taylor expansion and optimized by solving a linear\n",
    "system that has the form $A\\delta_p = b$, where $\\delta_p = (\\delta_u, \\delta_v)^\\top$ is the template offset.\n",
    "Please answer the following questions:\n",
    "1. What is $A^\\top A$? Using image gradient to derive it.\n",
    "2. What conditions must $A^\\top A$ meet so that the template offset can be calculated reliably? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2 Iterative KLT Tracker Implementation (50 pts)\n",
    "\n",
    "Complete the ``Iter_KLT`` method below, which computes the optimal local\n",
    "motion from frame $I_t$ to frame $I_{t+1}$ that minimizes the objective in Question 1. \n",
    "\n",
    "1. Note that moving the template rectangle by $u$ and $v$ will lead to fractional coordinates of the pixels. However, you need to extract information within the rectangle every time step, such as the image intensity, image gradient. To deal with this issue, you can convert the coordinates to integers, or perform some interpolations for floating numbers.\n",
    "\n",
    "2. You will also need to iterate the estimation until the change in $(u, v)$ is below a threshold, or reach a maximal iteration number. We set the threshold to be 0.005, and max iterations to be 1500. \n",
    "\n",
    "3. You can adjust every parameter you want to make the tracking more accurate.\n",
    "\n",
    "The rectangle in the first frame is $[x_1, y_1, x_2, y_2] = [318, 208, 418, 268]$. In other words, the rectangle starts from (318, 208) (row 208 and column 318 in the\n",
    "image) and ends at (418, 268). You need to understand the image coordinations correctly. \n",
    "\n",
    "If you complete this script correctly, it will play a video with a rectangle\n",
    "tracking the car. You can refer ``fig1.png``, ``fig2.png``, ``fig3.png`` for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def inbound(pt, rect):\n",
    "    return (pt[1] >= rect[0] and pt[1] <= rect[2] and pt[0] >= rect[1] and pt[0] <= rect[3])\n",
    "\n",
    "def Iter_KLT(I_t, I_t_1, rect, max_iter=1500, threshold=0.005):\n",
    "    '''\n",
    "    Input: \n",
    "        I_t: image frame at time t\n",
    "        I_t_1: image frame at time t+1\n",
    "        rect: tracking rectangle at time t\n",
    "        max_iter: maximum iteration steps for iterative KLT tracker\n",
    "        threshold: if delta_p's norm is smaller than the threshold, then the iterations will stop\n",
    "    \n",
    "    Return: \n",
    "        rect_new: tracking rectangle at time t+1\n",
    "        You need to compute \"delta_p\" as the translation for the rectangle from t to t+1\n",
    "    '''\n",
    "    u = 0\n",
    "    v = 0\n",
    "    img_h, img_w = I_t_1.shape[0], I_t_1.shape[1]\n",
    "    delta_p_length = 1000\n",
    "    rect_new = rect.copy()\n",
    "\n",
    "    # Extract image gradient at time t+1\n",
    "    Ix = cv2.Sobel(I_t_1, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    Iy = cv2.Sobel(I_t_1, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    iters = max_iter\n",
    "    delta_p = [0, 0]\n",
    "    iters = 0\n",
    "    \n",
    "    r_t = np.round(rect_new).astype(int)\n",
    "    I_t_feats = I_t[r_t[1]: r_t[3] + 1, r_t[0]: r_t[2] + 1]\n",
    "    \n",
    "    # Loop until \"delta_p\" is sufficiently small, or iteration number reaches max_iter\n",
    "    while delta_p_length > threshold and iters < max_iter:\n",
    "        if rect_new[0] < 0 or rect_new[1] < 0 or rect_new[2] >= img_w or rect_new[3] >= img_h:\n",
    "            print('Tracking rectangle out of boundary!', rect_new)\n",
    "            break\n",
    "            \n",
    "        ### You should calculate delta_p in the following codes\n",
    "        r = np.round(rect_new).astype(int)\n",
    "        I_t_1_feats = I_t_1[r[1]: r[3] + 1, r[0]: r[2] + 1]\n",
    "        \n",
    "        Ix_crop = Ix[r[1]: r[3] + 1, r[0]: r[2] + 1].flatten()\n",
    "        Iy_crop = Iy[r[1]: r[3] + 1, r[0]: r[2] + 1].flatten()\n",
    "        \n",
    "        G = np.array([Ix_crop, Iy_crop])\n",
    "        H = np.dot(G, G.T) \n",
    "        H_inv = np.linalg.inv(H)\n",
    "        err = -(I_t_1_feats - I_t_feats).flatten()\n",
    "        \n",
    "        delta_p = np.dot(H_inv, np.dot(G, err))\n",
    "        ### YOUR CODE ENDS\n",
    "        \n",
    "        u = u + delta_p[0]\n",
    "        v = v + delta_p[1]\n",
    "        delta_p_length = np.linalg.norm(delta_p)\n",
    "        rect_new = np.array([rect[0]+u, rect[1]+v, rect[2]+u, rect[3]+v])\n",
    "        iters += 1\n",
    "    \n",
    "    return np.round(rect_new).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"test.avi\")\n",
    "\n",
    "# Initialized tracking rectangle of the car\n",
    "rect = np.array([318, 208, 418, 268])\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "old_frame_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)/255.\n",
    "\n",
    "# A mask to draw the tracking rectangle for initialization\n",
    "mask = np.zeros_like(old_frame)\n",
    "mask = cv2.rectangle(mask, (rect[0], rect[1]), (rect[2], rect[3]), color=(0, 0, 255))\n",
    "img = cv2.add(old_frame, mask)\n",
    "cv2.imshow('frame',img)\n",
    "cv2.waitKey(30) & 0xff\n",
    "\n",
    "while(1):\n",
    "    # read video and turn it to grayscale using opencv\n",
    "    ret,frame = cap.read()\n",
    "    if ret is True:\n",
    "        cur_frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)/255.\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    rect_new = Iter_KLT(old_frame_gray, cur_frame_gray, rect)\n",
    "    \n",
    "    # Clear the mask to draw the tracking rectangle every step\n",
    "    mask = np.zeros_like(frame)\n",
    "    mask = cv2.rectangle(mask, (rect_new[0], rect_new[1]), (rect_new[2], rect_new[3]), color=(0, 0, 255), thickness=2)\n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # update old frame and tracking rectangle\n",
    "    old_frame_gray = cur_frame_gray.copy()\n",
    "    rect = rect_new.copy()\n",
    "\n",
    "cv2.destroyWindow('frame')\n",
    "cv2.waitKey(1)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3 Visualization (10 pts)\n",
    "\n",
    "Plot your tracking result (image + rectangle) at frame 5,\n",
    "frame 20, frame 50 and frame 90 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "pass\n",
    "### YOUR CODE ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 Moving Object Discovery (50 pts, contains 20 pts extra credit)\n",
    "\n",
    "In this problem, you are provided with a video game, which contains some moving objects as well as fixed objects, which is ``video_game.mp4``\n",
    "\n",
    "Design an algorithm that will find the moving objects in the video (30 pts).\n",
    "\n",
    "We do not have any specific requirements. Please do you best to achieve this open-ended task. However, following are some hints:\n",
    "\n",
    "1. Use optical flow method to compute the flow of the moving objects. You can use APIs provided in OpenCV, like https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html). To use the sample code in this link, you need to figure out a method to select the points of interest. Simply using the corner extraction will introduce some corners remain fixed for the video.\n",
    "\n",
    "2. You can represent a moving object in your own way. For example, you can use rectangles like in problem 1 / a binary mask / some keypoints / trajetories. You should select at least 5 representative frames, and plot the moving object in the frame. Binary masks and rectangles are usually more challenging, we will give more credits on that.\n",
    "\n",
    "3. Give detailed analysis based on your results. (Failure cases? Efficiency?) Propose a potential improvement.\n",
    "\n",
    "Requirements for extra credits (+20 pts):\n",
    "\n",
    "1. Propose novel solutions to handle the corner cases. \n",
    "2. Provide visualization of your improvements and give analysis on that.\n",
    "\n",
    "We understand that the approach description is vague. But we expect to witness your engineering skills to solve this problem :). Please treat it as a small \"final project\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
