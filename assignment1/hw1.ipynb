{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "In this homework, we will go through what we learned during the first three weeks, including basic linear algebra, least squares method, feature descriptor and matching, and bag of visual words.\n",
    "\n",
    "You should finish this homework in this `hw1.ipynb` file using our provided templates. You can add other functions to solve the problems if necessary, but please only add them in this file.\n",
    "\n",
    "The due for this homework is 12:00pm, Oct. 18th, Friday. We decided to prolong the time for you to finish this homework. Please submit this `hw1.ipynb` to Gradescope.\n",
    "\n",
    "In the assignment folder, you will see:\n",
    "- `features.py`, which contains some auxilary functions that help you extract and visualize keypoints;\n",
    "- `*.png` and `*.jpg` files, which are some images you will work on in the feature descriptor question;\n",
    "- `database` and `query` folders, which contain images of 5 classes selected from the famous ImageNet dataset, to be used to build bag of visual words for the last question;\n",
    "- `hw1.ipynb`, which is the file you will work on and submit. Please only write your answers here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import random  # pseudo random number generator library\n",
    "import numpy as np\n",
    "from skimage import filters  # if skimage not installed, try \"python3 -m pip install scikit-image\"\n",
    "from skimage.feature import corner_peaks\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "\n",
    "# This code is to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Numpy Practice (10 points)\n",
    "This question asks basic Numpy operations. Most questions already give you the right answer to check your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1 (2 points)\n",
    "Define the following using numpy:\n",
    "\n",
    "$$M = \\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9 \\\\\n",
    "10 & 11 & 12 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$a = \\begin{bmatrix}\n",
    "1 \\\\ 3 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$b = \\begin{bmatrix}\n",
    "-1 \\\\ 5 \\\\ 2\n",
    "\\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "Hint: \n",
    "1. in Numpy, a 1-dimensional vector represents a column vector\n",
    "2. if you want to review Numpy programming, check discussion 1 material on the course website (under the Schedule & Assignment tab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "M = None\n",
    "a = None\n",
    "b = None\n",
    "### END OF CODE\n",
    "print(\"M = \\n\", M)\n",
    "print(\"a = \\n\", a)\n",
    "print(\"b = \\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2 (2 points)\n",
    "Compute the dot product between $a$ and $b$ using numpy: $c = a^Tb$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "c = None\n",
    "# END OF CODE\n",
    "\n",
    "assert c == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3 (2 points)\n",
    "Compute $(a^T b)Ma$ using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "ans = None\n",
    "# END OF CODE\n",
    "\n",
    "assert ans[0] == 160 and ans[1] == 400 and ans[2] == 640 and ans[3] == 880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.4 (2 points)\n",
    "Perform Singular Value Decomposition with Numpy:\n",
    "$$M = U\\Sigma V^T$$\n",
    "In the equation above, $\\Sigma$ is a matrix with only diagonal elements, but in the question below, we only need the numbers on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Decompose M (4x3 matrix) into U,S,V. where U is a 4x4 matrix, VT is a 3x3 matrix, and S is the singular values (a vector of size 3, the diagnoal of Sigma)\n",
    "U,S,VT = None\n",
    "# END OF CODE\n",
    "\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.5 (2 points)\n",
    "Perform eigen decomposition on the following matrix.\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9 \\end{bmatrix}\n",
    "$$\n",
    "Find the largest eigenvalue and the corresponding eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "M = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "# YOUR CODE HERE\n",
    "eigen_values, eigen_vectors = None\n",
    "largest_eigen_value = None\n",
    "eigen_vector_for_largest_eigen_value = None\n",
    "# END OF CODE\n",
    "print(eigen_values)\n",
    "print(eigen_vectors)\n",
    "print(largest_eigen_value)\n",
    "print(eigen_vector_for_largest_eigen_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 2 Least Squares Method (20 points)\n",
    "\n",
    "## Question 2.1 Over-determined System and  Under-determined System (6 points)\n",
    "\n",
    "1. consider a system of 4 equations and 3 unknowns $(X, Y, Z)$, which is overdetermined (more equations than unknowns). (3 points)\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "-3 & 4 & 1 \\\\\n",
    "-1 & 10 & 3 \\\\\n",
    "-4 & 2 & 2\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "5 \\\\\n",
    "2 \\\\\n",
    "2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "2. consider a system of 2 equations and 3 unknowns $(X, Y, Z)$, which is underdetermined (fewer equations than unknowns). (3 points)\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-3 & 4 & 1 \\\\\n",
    "-1 & 10 & 3 \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "5 \\\\\n",
    "2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Find solutions for 1 and 2. If there is no solution, write down your proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down your calculation or proof of Question 2.1 here:\n",
    "<br></br>\n",
    "1) There is no solution to the system because the system is inconsistent as the following shows:\n",
    "\n",
    "\\begin{pmatrix}-4&2&2&2\\\\ 0&\\frac{19}{2}&\\frac{5}{2}&\\frac{3}{2}\\\\ 0&0&\\frac{28}{19}&\\frac{32}{19}\\\\ 0&0&0&\\frac{31}{7}\\end{pmatrix}\n",
    "Thus, because the system is inconsistent as 0 does not equal 31.\n",
    "<br></br>\n",
    "\n",
    "2)\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 Compute Pseudo Inverse (2 points)\n",
    "\n",
    "Implement the get_pinv method, which takes a matrix as input, and outputs its pseudo inverse. Please call get_pinv (written by yourself) to calculate the pseudo-inverse of the two matrices:\n",
    "\n",
    "$$\n",
    "A_1 = \\begin{bmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "-3 & 4 & 1 \\\\\n",
    "-1 & 10 & 3 \\\\\n",
    "-4 & 2 & 2\\\\\n",
    "\\end{bmatrix}, A_2 = \\begin{bmatrix}\n",
    "-3 & 4 & 1 \\\\\n",
    "-1 & 10 & 3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "(Hint: $A^\\dagger = V\\Sigma^{-1}U^T$)  \n",
    "You may use np.linalg.svd, but you may not use np.linalg.pinv. (You may secretly use it to check you answer. We won't know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pinv(matrix):\n",
    "    \"\"\" Implement the pseudo inverse of a matrix\n",
    "    Args:\n",
    "        matrix: a numpy array with shape (m,n)\n",
    "\n",
    "    Returns:\n",
    "        out: the pseudo inverse of input matrix\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    out = None\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1 = np.array([[2, 1, 1], [-3,4,1],[-1, 10, 3], [-4, 2, 2]])\n",
    "A_2 = np.array([[-3,4,1], [-1, 10, 3]])\n",
    "pinv_A_1 = get_pinv(A_1)\n",
    "pinv_A_2 = get_pinv(A_2)\n",
    "print(pinv_A_1)\n",
    "print(pinv_A_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3 Least squares solution for an over-determined system (4 points)\n",
    "For an over-determined linear system $Ax = b$ where $A\\in\\mathbb{R}^{m\\times n}, m>n$, there may not be any solution. However, we can formulate the following least square problem to obtain the best approximation that minimizes the residual of $Ax-b$:\n",
    "\n",
    "$$\\min_x \\|Ax - b\\|^2$$\n",
    "\n",
    "1. Show that $A^\\dagger = (A^T A)^{-1}A^T$ for a tall $A$ matrix. (Hint: check the hint of Question 2.1)\n",
    "2. Show that the solution to the above optimization can be written using the pseudo-inverse $A^\\dagger$ of matrix $A$: $x=A^\\dagger b$ (Hint: Calculate gradient to $x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down your proof of Question 2.2 here:\n",
    "<br></br>\n",
    "1. \n",
    "We know that $A^\\dagger = V\\Sigma^{-1}U^T$ (1)\n",
    "<br></br>\n",
    "In order to show that $A^\\dagger = (A^T A)^{-1}A^T$ (2), we expand this equation and attempt to simplify to the previous equation.\n",
    "$A^\\dagger = ((V^T \\Sigma U)(U \\Sigma V^T))^{-1}(V \\Sigma U^T)$\n",
    "<br></br>\n",
    "$= (V \\Sigma U^T U \\Sigma V^T)^{-1} (V \\Sigma U^T)$\n",
    "<br></br>\n",
    "$= V \\Sigma^{-2} V^T V \\Sigma U^T$\n",
    "<br></br>\n",
    "$= V \\Sigma^{-1} U^T$\n",
    "<br></br>\n",
    "We are able to expand and simplify equation (2) into equation (1), and thus prove that $A^\\dagger = (A^T A)^{-1}A^T$ \n",
    "<br></br>\n",
    "<br></br>\n",
    "2. \n",
    "https://ucsd-cse-152.github.io/discussion/discussion2.pdf\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 Minimum norm solution for an under-determined system (6 points)\n",
    "For an under-determined system $Ax = b$ where $A\\in\\mathbb{R}^{m\\times n}, m < n$, there can be infinite solutions (in fact, a linear space), thus we cannot return a unique answer. However, there is one solution that has the minimum $\\ell_2$-norm. The minimum norm solution is obtained by solving this optimization problem:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\min_{x} & &\\|x\\|^2\\\\\n",
    "& \\text{subject to} & &Ax - b = 0\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "1. Show that $$A^\\dagger = A^T(AA^T)^{-1}$$ for a fat matrix.\n",
    "2. Prove that for underdetermined system, $A^\\dagger b$ gives the optimal solution to the minimum norm problem. (Hint: Use the Lagrangian multipliers method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down your proof of Question 2.3 here:\n",
    "<br></br>\n",
    "https://ucsd-cse-152.github.io/discussion/discussion2.pdf\n",
    "<br></br>\n",
    "https://see.stanford.edu/materials/lsoeldsee263/08-min-norm.pdf\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5 Finish the calculation (2 points)\n",
    "Implement a method called linear_solver, to solve the least squares problem or minimum norm problem for $Ax = b$. \n",
    "\n",
    "It takes matrix $A, b$ as input, and output a vector, which is the solution. For the linear equations in Question 2.1, use this solver to compute the solution for least squares problem (2.1.1) or minimum norm problem (2.1.2).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_solver(matrix, vector):\n",
    "    \"\"\" Implement a linear solver of a least squares problem/minimum norm problem\n",
    "    Args:\n",
    "        matrix: input matrix on LHS\n",
    "        vector: target vector on RHS\n",
    "    Returns:\n",
    "        out: the solution for least squares problem/minimum norm problem\n",
    "    \"\"\"\n",
    "    p_inv = get_pinv(matrix)\n",
    "    ### YOUR CODE HERE\n",
    "    out = None\n",
    "    ### END YOUR CODE\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_1 = np.array([[2, 1, 1], [-3, 4, 1],[-1, 10, 3], [-4, 2, 2]])\n",
    "A_2 = np.array([[-3, 4, 1], [-1, 10, 3]])\n",
    "b_1 = np.array([1, 5, 2, 2])\n",
    "b_2 = np.array([5, 2])\n",
    "ls_res = linear_solver(A_1, b_1)\n",
    "min_norm_res = linear_solver(A_2, b_2)\n",
    "print('least square result', ls_res)\n",
    "print('minimum norm result', min_norm_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Local Feature Descriptors and Matching (30 points)\n",
    "\n",
    "In this part, you will be implementing keypoint detector, feature descriptors,\n",
    "and feature matching. Keypoint detectors find salient points in an image, such\n",
    "as corners. Using information surrounding a keypoint, we can extract a feature descriptor. Once we\n",
    "have descriptors, we can use them to match keypoints between images by measuring feature similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequesite: Image Filtering and Box filter\n",
    "Load the `chair.png` image and we can smooth it by a $5\\times 5$ box filter by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "from skimage import filters\n",
    "\n",
    "I = imread('chair.jpg', as_grey=True)\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "plt.title('original image')\n",
    "plt.show()\n",
    "\n",
    "window_size = 5\n",
    "box_filter=np.ones((window_size, window_size))/(window_size*window_size) # define a box filter\n",
    "from scipy.signal import convolve\n",
    "I_box = convolve(I, box_filter, mode='same')\n",
    "plt.imshow(I_box)\n",
    "plt.axis('off')\n",
    "plt.title('box smoothed image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not need to flip the kernel when using the convolve function provided by scipy.signal, because this function really just does the `correlation` (or filtering) operation, instead of the true `convolution` defined in math books. Nonetheless, let us just get used to this engineering convention and call the scipy.signal.convolve to compute the filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1 Vertical Edge filter (5 points)\n",
    "\n",
    "Use you favorate vertical edge filter to extract vertical edges from the `chair.jpg` image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('chair.jpg', as_grey=True)\n",
    "I_vert_edge = None\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "### END YOUR CODE\n",
    "\n",
    "plt.imshow(I_vert_edge)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2 Harris Corner Detector and Feature Matching (15 points)\n",
    "In this question, you are going to implement Harris corner detector for keypoint localization. Review the lecture slides on Harris corner detector to understand how it works. The Harris detection algorithm can be divide into the following steps:\n",
    "1. Compute $x$ and $y$ derivatives ($I_x, I_y$) of an image\n",
    "2. Compute products of derivatives ($I_x^2, I_y^2, I_{xy}$) at each pixel\n",
    "3. Compute matrix $M$ at each pixel, where\n",
    "$$\n",
    "M(x_0,y_0) = \\sum_{x,y} w(x-x_0,y-y_0)\n",
    "    \\begin{bmatrix}\n",
    "        I_{x}^2 & I_{x}I_{y} \\\\\n",
    "        I_{x}I_{y} & I_{y}^2\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "Here, we set weight $w(x,y)$ to be a box filter of size $3 \\times 3$ (the box is placed centered at $(x_0, y_0)$).\n",
    "\n",
    "This looks slightly more complicated than what we taught in class. But if you stare at the equation for a while, you will realize that this is just the \"smoothed\" version of the $M$ we taught in class, smoothed by a box filter $w$. Obviously, the smoothing should be done by a filtering operation.\n",
    "4. Compute corner response $R=Det(M)-k(Trace(M)^2)$ at each pixel\n",
    "5. Output corner response map $R(x,y)$\n",
    "\n",
    "\n",
    "Step 1 is already done for you in the function **`harris_corners`**. You need to complete the function implementation and run the code below.\n",
    "\n",
    "- Hint: You may use the function `scipy.signal.convolve`.  \n",
    "You may refer to `chair_harris_ground_truth.png` for the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_corners(img, window_size=3, k=0.04):\n",
    "    \"\"\"\n",
    "    Compute Harris corner response map. Follow the math equation\n",
    "    R=Det(M)-k(Trace(M)^2).\n",
    "\n",
    "    Hint:\n",
    "        You may use the function scipy.signal.convolve,\n",
    "        which is already imported above\n",
    "\n",
    "    Args:\n",
    "        img: Grayscale image of shape (H, W)\n",
    "        window_size: size of the window function\n",
    "        k: sensitivity parameter\n",
    "\n",
    "    Returns:\n",
    "        response: Harris response image of shape (H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    H, W = img.shape\n",
    "    window = np.ones((window_size, window_size))\n",
    "\n",
    "    response = np.zeros((H, W))\n",
    "\n",
    "    dx = filters.sobel_v(img)\n",
    "    dy = filters.sobel_h(img)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('chair.jpg', as_grey=True)\n",
    "\n",
    "# Compute Harris corner response\n",
    "response = harris_corners(img)\n",
    "\n",
    "# Display corner response\n",
    "plt.imshow(response)\n",
    "plt.axis('off')\n",
    "plt.title('Harris Corner Response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.3 Histogram of Oriented Gradients (10 points)\n",
    "In this section, you are going to implement a simplified version of HOG descriptor. Similar to the SIFT feature introduced in class, HoG is also based on image gradients but with fewer engineering tricks. We implement (a simplied) HoG instead of SIFT to get some taste of image feature engineering.\n",
    "\n",
    "HOG stands for Histogram of Oriented Gradients (Histograms of oriented gradients for human detection, by N. Dalal and B. Triggs). In HOG descriptor, the distribution (histograms) of directions of gradients (oriented gradients) are used as features. Gradients (x and y derivatives) of an image are useful because the magnitude of gradients is large around edges \n",
    "and corners (regions of abrupt intensity changes) and we know that edges and corners pack in a lot more information about object shape than flat regions.\n",
    "The steps of HOG are:\n",
    "1. compute the gradient image in x and y  \n",
    "    Use the sobel filter provided by `skimage.filters.sobel_h` and `skimage.filters.sobel_v`\n",
    "2. compute gradient histograms  \n",
    "    Divide image into patches, each of which contains $16 \\times 16$ pixels. \n",
    "3. A patch is then evenly partitioned as $2 \\times 2$ cells. Then calculate the histogram of gradients in each cell, with each cell contains $8 \\times 8$ pixels. Normalize the gradient vector in each cell to be a unit vector. \n",
    "4. concatenate the unit vectors of each cell in a patch to be a single vector for encoding the patch\n",
    "\n",
    "The function `corner_peaks` from `skimage.feature` performs non-maximum suppression to take local maxima of the response map and localize keypoints. You can just regard this function as a keypoint selection module given some manually designed thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_euclidean_distance(feature1, feature2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        feature1: numpy array with shape (N, k)\n",
    "        feature2: numpy array with shape (M, k)\n",
    "    Returns:\n",
    "        S: numpy array with shape (N, M) where S[i,j] is the l2 distance between feature1[i] and feature2[j]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    S = None\n",
    "    # END OF CODE\n",
    "    return S\n",
    "    \n",
    "\n",
    "def hog_descriptor(patch, pixels_per_cell=(8,8)):\n",
    "    \"\"\"\n",
    "    Generating hog descriptor by the following steps:\n",
    "\n",
    "    1. compute the gradient image in x and y (already done for you)\n",
    "    2. compute gradient histograms\n",
    "    3. normalize across cells\n",
    "    4. flattening cells into a feature vector\n",
    "\n",
    "    Args:\n",
    "        patch: grayscale image patch of shape (h, w)\n",
    "        pixels_per_cell: size of a cell with shape (m, n)\n",
    "\n",
    "    Returns:\n",
    "        cells: 1D array of shape ((h*w*n_bins)/(m*n))\n",
    "    \"\"\"\n",
    "    assert (patch.shape[0] % pixels_per_cell[0] == 0), \\\n",
    "        'Heights of patch and cell do not match'\n",
    "    assert (patch.shape[1] % pixels_per_cell[1] == 0), \\\n",
    "        'Widths of patch and cell do not match'\n",
    "\n",
    "    n_bins = 9\n",
    "    degrees_per_bin = 180 // n_bins\n",
    "\n",
    "    Gx = filters.sobel_v(patch)\n",
    "    Gy = filters.sobel_h(patch)\n",
    "\n",
    "    # Unsigned gradients\n",
    "    G = np.sqrt(Gx**2 + Gy**2)\n",
    "    theta = (np.arctan2(Gy, Gx) * 180 / np.pi) % 180\n",
    "\n",
    "    G_cells = view_as_blocks(G, block_shape=pixels_per_cell) # view_as_blocks is a function from skimage, which partitions a patch G into cells of pixels_per_cell size\n",
    "    theta_cells = view_as_blocks(theta, block_shape=pixels_per_cell)\n",
    "    rows = G_cells.shape[0]\n",
    "    cols = G_cells.shape[1]\n",
    "\n",
    "    cells = np.zeros((rows, cols, n_bins))\n",
    "\n",
    "    # Compute histogram per cell\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import describe_keypoints, plot_matches, match_descriptors\n",
    "from skimage.util.shape import view_as_blocks\n",
    "\n",
    "img1 = imread('uttower1.jpg', as_grey=True)\n",
    "img2 = imread('uttower2.jpg', as_grey=True)\n",
    "\n",
    "# Detect keypoints in both images\n",
    "keypoints1 = corner_peaks(harris_corners(img1, window_size=3),\n",
    "                          threshold_rel=0.05,\n",
    "                          exclude_border=8)\n",
    "keypoints2 = corner_peaks(harris_corners(img2, window_size=3),\n",
    "                          threshold_rel=0.05,\n",
    "                          exclude_border=8)\n",
    "\n",
    "# Extract features from the corners\n",
    "desc1 = describe_keypoints(img1, keypoints1,\n",
    "                           desc_func=hog_descriptor,\n",
    "                           patch_size=16)\n",
    "\n",
    "desc2 = describe_keypoints(img2, keypoints2,\n",
    "                           desc_func=hog_descriptor,\n",
    "                           patch_size=16)\n",
    "\n",
    "# Match descriptors in image1 to those in image2. \n",
    "# You can read into match_descriptors and adjust the last parameter to see what will happen, which is a threshold for screening correspondences\n",
    "matches = match_descriptors(desc1, desc2, pairwise_euclidean_distance, 0.75)\n",
    "\n",
    "# Plot matches\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "ax.axis('off')\n",
    "plot_matches(ax, img1, img2, keypoints1, keypoints2, matches)\n",
    "plt.show()\n",
    "# compare your result with the provided `correspondence_ref_result.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Visual Words and Image Retrieval (40 points)\n",
    "\n",
    "We are now able to extract features using a simplified HOG. The next question is, how can we discribe an image by our feature discriptor? Recall what we learned about visual words, we can build a visual vocabulary by clustering the local features.\n",
    "\n",
    "## Question 4.1: 1-D KMeans (5 points)\n",
    "\n",
    "Consider a very simple one-dimensional dataset. The data points are **2, 5, 12, 20, 23, 26**.\n",
    "\n",
    "Run the algorithm using two clusters, where the initial guesses for the cluster centers are 3.5 (cluster 1) and 5.0 (cluster 2).\n",
    "For each step of the K-Means algorithm, specify the entries in each cluster and calculate the new mean\n",
    "below. Assume that a step consists of assigning points to each cluster and computing the new mean. If it\n",
    "converges in fewer than five steps, you may leave the remaining steps blank.\n",
    "\n",
    "You can manually calculate the answers or write an program. You only need to provide a final answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "\n",
    "Cluster index of [2, 5, 12, 20, 23, 26]:  [1, 2, 2, 2, 2, 2] (an example here)\n",
    "\n",
    "Cluster 1 new mean:\n",
    "\n",
    "Cluster 2 new mean:\n",
    "\n",
    "Step 2:\n",
    "\n",
    "Cluster index of [2, 5, 12, 20, 23, 26]:\n",
    "\n",
    "Cluster 1 new mean:\n",
    "\n",
    "Cluster 2 new mean:\n",
    "\n",
    "Step 3:\n",
    "\n",
    "Cluster index of [2, 5, 12, 20, 23, 26]:\n",
    "\n",
    "Cluster 1 new mean:\n",
    "\n",
    "Cluster 2 new mean:\n",
    "\n",
    "Step 4:\n",
    "\n",
    "Cluster index of [2, 5, 12, 20, 23, 26]:\n",
    "\n",
    "Cluster 1 new mean:\n",
    "\n",
    "Cluster 2 new mean:\n",
    "\n",
    "Step 5:\n",
    "\n",
    "Cluster index of [2, 5, 12, 20, 23, 26]:\n",
    "\n",
    "Cluster 1 new mean:\n",
    "\n",
    "Cluster 2 new mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.2: Construct Visual Words\n",
    "\n",
    "There are four steps for you to construct the visual words for an image\n",
    "\n",
    "1. Divide an image into patches\n",
    "2. Cluster the patches through K-Means and build the visual vocabulary\n",
    "3. Index patches by the ID of the nearest cluster center (visual word)\n",
    "4. Build a histogram of visual words by aggregating cluster IDs of patches in the entire image\n",
    "\n",
    "We first implement a function to load all images in a folder for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_image(image_path):    \n",
    "    files = os.listdir(image_path)\n",
    "    images = []\n",
    "    for fi in files:\n",
    "        if fi.endswith('.JPEG') or fi.endswith('.jpg') or fi.endswith('.jpeg'):\n",
    "            image = imread(os.path.join(image_path, fi), as_grey=False)\n",
    "            images.append(image)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = read_image('./database')\n",
    "plt.imshow(all_images[0])  # have a look at the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Images to patches (5 points)\n",
    "Implement the following function based on the comments. \n",
    "You may use any function from `sklearn.feature_extraction`, but it is not required.\n",
    "\n",
    "The input images are already resized to $256\\times 256\\times 3$. Decompose each image densely and evenly as patches without overlapping. The patch_size by default is $16$, which is both the width and height of the patch. As a result, there should be $16\\times 16$ patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_patches(images, patch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        images: numpy array with shape (N, H, W, 3)  where N is total number of images, H is width, W is height\n",
    "        patch_size: size of a square patch (patch_size, patch_size) \n",
    "\n",
    "    Returns:\n",
    "        patches: numpy array with shape (M, 16, 16, 3) where M is total number of patches (a lot)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    patches = None\n",
    "    ### END OF CODE\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = images_to_patches(all_images, 16)\n",
    "color_patches = patches.reshape([-1, 16*16*3])  # (M, 768), each patch is represented by flattened color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 KMeans (5 points)\n",
    "You need to implement the `fit_kmeans` function to fit color_patches.\n",
    "\n",
    "You may use `sklearn.cluster.KMeans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_kmeans(data, n_clusters=100):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: numpy array with shape (N, k), N is the number of data points, k is the dimension of feature vector.\n",
    "        n_clusters: cluster number\n",
    "\n",
    "    Returns:\n",
    "        out: sklearn.cluster.KMenas model\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    kmeans = None\n",
    "    ### END OF CODE\n",
    "    \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run kmeans on patches to build the visual vocabulary. (It will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = fit_kmeans(color_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Plot clusters (5 points)\n",
    "Randomly choose 10 clusters from the Kmeans result. Plot 5 original patches ($16\\times 16\\times 3$) displayed in color for each of the clusters.\n",
    "Hint: use the `predict` function from `sklearn.cluster.KMeans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# plt.subplot(...\n",
    "### END OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Visual word (10 points)\n",
    "Implement `get_patch_indices` and `get_visual_words` functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_indices(patches, kmeans_model):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            patches: numpy array with shape (N, 16, 16, 3), where N is the number of batches\n",
    "            kmeans_model: already fitted k-means model\n",
    "\n",
    "        Returns:\n",
    "            ind: the cluster indices that the patches belong to\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    ind = None\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return ind\n",
    "\n",
    "\n",
    "def get_visual_words(image, kmeans_model, patch_size=16):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image: numpy array with shape (H, W, 3), which is a single image\n",
    "        kmeans_model: the fitted kmeans model\n",
    "        patch_size: size of a square patch\n",
    "\n",
    "    Returns:\n",
    "        hist: histogram of visual words that describes the images\n",
    "    \"\"\"\n",
    "    patches = images_to_patches(image[None, :], patch_size=patch_size) \n",
    "    # image[None, :] means expand the shape (H, W, 3) to (1, H, W, 3), so that is will fit your previous implementation of images_to_patches\n",
    "    visual_words = get_patch_indices(patches, kmeans_model)\n",
    "    \n",
    "    # build histogram\n",
    "    hist = None\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read 5 query images from the `./query` foler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = read_image('./query')\n",
    "for i in range(test_images.shape[0]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 Image retrieval (10 points)\n",
    "For each image in the `./database` folder, compute its bag of visual words representation. Then for each image in the `./query` folder, compute its bag of visual words representation.\n",
    "\n",
    "For each test image, find 5 most similar images from the `./database` folder using cosine similarity between their bag of visual words representations, and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visual_words = np.array([get_visual_words(img, kmeans_model) for img in all_images])\n",
    "all_test_words = np.array([get_visual_words(img, kmeans_model) for img in test_images])\n",
    "\n",
    "### YOUR CODE HERE\n",
    "pass\n",
    "### END OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice any unexpected retrival results? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6 Extra Credit (15 points)\n",
    "Perform the whole image retrieval pipeline (4.2.1 - 4.2.5) with hog features. What are the differences in the final results compared to the color features? Explain.\n",
    "\n",
    "Hint: load images in gray scale and perform the pipeline with gray scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
